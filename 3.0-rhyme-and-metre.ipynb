{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt \n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=False)\n",
    "\n",
    "from src.utils import print2_list, print2, export_ipynb_for_github_pages\n",
    "from src.plotly import plot_histogram, plot_timeline, plot_horizontal_bar, plot_heatmap\n",
    "from src.data import load_data\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "df = load_data('data/comments.txt', False)\n",
    "df = df[df['type']=='poem']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "comments = df['poem'].str.cat(sep=' ')\n",
    "tokens = tokenizer.tokenize(comments)\n",
    "tokens = [t for t in tokens if not t in stop_words]\n",
    "frequency_dist = nltk.FreqDist(tokens)\n",
    "most_common = frequency_dist.most_common(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_horizontal_bar(\n",
    "    labels = [x[0] for x in most_common[::-1]],\n",
    "    values = [x[1] for x in most_common[::-1]],\n",
    "    title = 'Most occuring words in comments by u/poem_for_your_sprog',\n",
    "    xaxis_title = 'Occurence',\n",
    "    yaxis_title='')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about Timmy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_about_timmy = np.array(['timmy' in comment for comment in df['poem']])\n",
    "comments_about_timmy_fucking_dying = np.array(['timmy fucking died' in comment for comment in df['poem']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comments about Timmy: {}'.format(comments_about_timmy.sum()))\n",
    "print('Comments about Timmy fucking dying: {}'.format(comments_about_timmy_fucking_dying.sum()))\n",
    "print('Comments about Timmy that do not end with Timmy fucking dying: {}'\n",
    "      .format(comments_about_timmy.sum()-comments_about_timmy_fucking_dying.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "                    go.Pie(\n",
    "                        labels=['Timmy fucking dying','Timmy not fucking dying'], \n",
    "                        values=[comments_about_timmy_fucking_dying.sum(),\n",
    "                             comments_about_timmy.sum()-comments_about_timmy_fucking_dying.sum()], hole=.3\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.update_layout(\n",
    "        template='simple_white'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So.. What happens to Timmy if he doesn't fucking die?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timmy_not_dying = df[(comments_about_timmy) & (~comments_about_timmy_fucking_dying)]\n",
    "df_timmy_not_dying['ending'] = [x.split('>')[-1] for x in df_timmy_not_dying['poem']]\n",
    "df_timmy_not_dying = df_timmy_not_dying.sort_values('ups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_horizontal_bar(\n",
    "    labels = df_timmy_not_dying['ending'],\n",
    "    values = df_timmy_not_dying['ups'],\n",
    "    title = 'Best scoring alternative endings to poems about Timmy',\n",
    "    xaxis_title = 'Upvotes',\n",
    "    yaxis_title=''\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rhyming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_word_per_line(poem):\n",
    "    return [re.findall(r\"\\s([^\\.?!,\\s]+)[\\.?!,\\s']*$\",line)[0] if re.findall(r\"\\s([^\\.?!,\\s]+)[\\.?!,\\s']*$\",line) else None \n",
    "     for line in poem.split('>')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_words_list = [get_last_word_per_line(mystr) for mystr in df['poem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def get_rhyme_scheme(last_words_per_line):\n",
    "    alphabet = string.ascii_lowercase\n",
    "    rhyme_scheme = np.empty(len(last_words_per_line),dtype=str)\n",
    "    k=0\n",
    "    for i in range(len(last_words_per_line)):\n",
    "        if rhyme_scheme[i]=='':\n",
    "            if last_words_per_line[i] is not None:\n",
    "                rhyme_scheme[i]=alphabet[k % 26]\n",
    "                rhyme_list = pronouncing.rhymes(last_words_per_line[i])\n",
    "                rhyme_scheme[(np.array([x in rhyme_list for x in last_words_per_line]) & (rhyme_scheme == ''))] = alphabet[k % 26]\n",
    "                k+=1\n",
    "            else:\n",
    "                rhyme_scheme[i] = '?'               \n",
    "    return ''.join(rhyme_scheme) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhyme_schemes = [get_rhyme_scheme(x) for x in last_words_list]\n",
    "df['rhyme_scheme'] = rhyme_schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_rhyme_schemes = df['rhyme_scheme'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_horizontal_bar(\n",
    "    labels = most_common_rhyme_schemes.index[::-1],\n",
    "    values = most_common_rhyme_schemes[::-1],\n",
    "    title = 'The 15 most common rhyming schemes in poems by /u/poem_for_your_sprog',\n",
    "    xaxis_title = 'Number of poems',\n",
    "    yaxis_title='',\n",
    "    figsize=(800,600)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_rhymes = df[df['rhyme_scheme'].isin(most_common_rhyme_schemes.index[:10])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_rhymes = (df_top_rhymes\n",
    "                 .groupby([\"rhyme_scheme\"])\n",
    "                 .apply(lambda x: x.sort_values([\"ups\"], ascending = False))\n",
    "                 .reset_index(drop=True)\n",
    "                 .groupby('rhyme_scheme')\n",
    "                 .head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for rhyme_scheme in most_common_rhyme_schemes.index[:10]:\n",
    "    df_subset = df_top_rhymes[df_top_rhymes['rhyme_scheme'] == rhyme_scheme]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_subset['average_line_length'],\n",
    "        y=df_subset['ups'],\n",
    "        mode='markers',\n",
    "        name=rhyme_scheme,\n",
    "        marker=dict(\n",
    "            size = 8,\n",
    "            line_width=1,\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        hoverinfo = 'text',\n",
    "        text=[re.sub('>','<br>',comment) for comment in df_subset['poem']]\n",
    "    )\n",
    " )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Top rated poems in the 10 most common rhyming schemes by u/poem_for_your_sprog',\n",
    "    title_x=0.5,\n",
    "    template='simple_white',\n",
    "    xaxis_title='Average line length',\n",
    "    yaxis_title='Upvotes'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rhyme sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rhyme_tuples(last_words_per_line):\n",
    "    all_rhymes = list()\n",
    "    for i in range(len(last_words_per_line)-1):\n",
    "        if last_words_per_line[i] is not None:\n",
    "            rhymes_with = pronouncing.rhymes(last_words_per_line[i])\n",
    "            next_words = last_words_per_line[(i+1):np.min([len(last_words_per_line),i+4])]\n",
    "            index_of_next_rhyme_words = np.where([x in rhymes_with for x in next_words])[0]\n",
    "            if index_of_next_rhyme_words.size>0:\n",
    "                all_rhymes.append((last_words_per_line[i], next_words[index_of_next_rhyme_words[0]]))\n",
    "    return all_rhymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "all_rhyme_tuples = [get_rhyme_tuples(x) for x in last_words_list]\n",
    "all_rhyme_tuples = reduce(lambda x,y: x+y,all_rhyme_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rhyme_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rhyme_words = [x for tpl in all_rhyme_tuples for x in tpl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rhyme_words = pd.DataFrame({'word':all_rhyme_words})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rhyme_words.groupby('word')['word'].count().sort_values(ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_scansion(word):\n",
    "    \"\"\" \n",
    "    Get the scansion per word, as a string of 0's and 1's.\n",
    "    \"\"\"\n",
    "    word = word.strip(punctuation)\n",
    "    if word == '': \n",
    "        return ''\n",
    "    pronounciation = pronouncing.phones_for_word(word)\n",
    "    if pronounciation: \n",
    "        stresses = pronouncing.stresses(pronounciation[0])\n",
    "    else:\n",
    "        word = re.sub(\"'.+\",'',word)\n",
    "        pronounciation = pronouncing.phones_for_word(word)\n",
    "        if pronounciation: \n",
    "            stresses = pronouncing.stresses(pronounciation[0])\n",
    "        else:\n",
    "            stresses = '?'\n",
    "    return re.sub('2','1',stresses)\n",
    "\n",
    "def get_line_scansion(line):\n",
    "    \"\"\" \n",
    "    Get the scansion per line, as a string of 0's and 1's.\n",
    "    \"\"\"\n",
    "    return ''.join([get_word_scansion(word) for word in line.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * = acatalectic, i.e. the last (unstressed) syllable is omitted\n",
    "# ** = iambic subsitution, i.e. the first (unstressed) syllable is omitted from an anapestic foot\n",
    "\n",
    "known_metres = {\n",
    "    'iambic hexameter'       : '010101010101',\n",
    "    'iambic pentameter'      : '0101010101',\n",
    "    'iambic tetrameter'      : '01010101',\n",
    "    'iambic trimeter'        : '010101',\n",
    "    'iambic dimeter'         : '0101',\n",
    "    'iambic meter'           : '01',\n",
    "    \n",
    "    'anapestic tetrameter'   : '001001001001',\n",
    "    'anapestic tetrameter**' : '01001001001',\n",
    "    'anapestic trimeter'     : '001001001',\n",
    "    'anapestic trimeter**'   : '01001001',\n",
    "    'anapestic dimeter'      : '001001',\n",
    "    'anapestic dimeter**'    : '01001',\n",
    "    'anapestic meter'        : '001',\n",
    "\n",
    "    'trochaic hexameter'     : '101010101010',\n",
    "    'trochaic hexameter*'    : '10101010101',\n",
    "    'trochaic pentameter'    : '1010101010',\n",
    "    'trochaic pentameter*'   : '101010101',\n",
    "    'trochaic tetrameter'    : '10101010',\n",
    "    'trochaic tetrameter*'   : '1010101',\n",
    "    'trochaic trimeter'      : '101010',\n",
    "    'trochaic trimeter*'     : '10101',\n",
    "    'trochaic bimeter'       : '1010',\n",
    "    'trochaic bimeter*'      : '101',\n",
    "    'trochaic meter'         : '10',\n",
    "}\n",
    "kown_metres_inv = inv_map = {v: k for k, v in known_metres.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scansion = [[get_line_scansion(line) for line in poem.split('>')] for poem in df['poem']]\n",
    "df['scansion'] = [list(filter(bool, x)) for x in scansion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_line_scansions(scansion_list):\n",
    "    \"\"\" \n",
    "    Combines multiple shorter lines into a single line, if the number of syllables is equal.\n",
    "    This turns for example the following list of scansions per line;\n",
    "    \n",
    "    ['11101001011',\n",
    "     '11101011001',\n",
    "     '111011',\n",
    "     '11011']\n",
    "     \n",
    "     into\n",
    "     \n",
    "     ['11101001011',\n",
    "      '11101011001',\n",
    "      '11101111011']\n",
    "    \n",
    "    \"\"\"   \n",
    "    scansion_list = scansion_list.copy()\n",
    "    \n",
    "    improvement_found = True\n",
    "    while improvement_found:\n",
    "        # Find which lines to combine into one, if any.\n",
    "        n_syllables_per_line = [len(x) for x in scansion_list]\n",
    "        unique_line_lengths = sorted(np.unique(np.array(n_syllables_per_line)), key=lambda item: -item)\n",
    "        for target_length in unique_line_lengths[:np.min([len(unique_line_lengths),2])]:\n",
    "            for lines_to_combine in [2,3,4]: # try to combine 2,3 or 4 lines.\n",
    "                idx_line_to_combine = []\n",
    "                if lines_to_combine<len(scansion_list):\n",
    "                    combined_line_lengths = np.convolve(n_syllables_per_line,np.ones(lines_to_combine,dtype=int),'valid')\n",
    "                    idx_line_to_combine = np.where(combined_line_lengths==target_length)[0]\n",
    "                    if len(idx_line_to_combine)>0: break\n",
    "            if len(idx_line_to_combine)>0: break\n",
    "\n",
    "        if len(idx_line_to_combine)>0:\n",
    "            improvement_found = True\n",
    "            new_line = ''.join(scansion_list[idx_line_to_combine[0]:(idx_line_to_combine[0]+lines_to_combine)])\n",
    "            scansion_list[idx_line_to_combine[0]] = new_line\n",
    "            del scansion_list[(idx_line_to_combine[0]+1):(idx_line_to_combine[0]+lines_to_combine)]\n",
    "        else:\n",
    "            improvement_found = False\n",
    "            \n",
    "    return scansion_list\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scansion_altered'] = [combine_line_scansions(x) for x in df['scansion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_non_stressed(a,b):\n",
    "    return sum ((a[i] == '0') and (b[i] == '0') for i in range(len(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_known_metre(scansion_list):\n",
    "    \"\"\"\n",
    "    Use a list of scansion per line to estimate the metre of the poem. The assumption is \n",
    "    that a poem always has at most two different known metres. Furthermore, since our method of\n",
    "    identifying the scansion overestimates the number of stressed syllables, we will use the number\n",
    "    of accurate non-stressed syllables to determine the known metre.\n",
    "    \"\"\"\n",
    "    # First, create metre_list; a list which elements have the structure [a,b] where a is the number \n",
    "    # of syllables in the line, and b a list of the most likely know metres.\n",
    "    metre_list=[]\n",
    "    for scansion in scansion_list:\n",
    "        l = [(same_non_stressed(scansion,k),v) for k, v in kown_metres_inv.items() if len(k) == len(scansion)]    \n",
    "        if l:\n",
    "            maxValue = max(l, key=lambda x: x[0])[0]\n",
    "            maxValueList = [x[1] for x in l if x[0] == maxValue]\n",
    "            metre_list.append([len(scansion),maxValueList])\n",
    "\n",
    "    # If metre_list has at least one element, create metres_list. The elements in this list\n",
    "    # contain per line length all the predicted metres, still to be flattened.\n",
    "    # If more than two elements, we only look at the stats for the two highest line lengths.\n",
    "    # this is to filter outliers, if in some shorter lines the metre was not found and thus they\n",
    "    # could not be combined.\n",
    "    if metre_list:        \n",
    "        (values,counts) = np.unique([x[0] for x in metre_list],return_counts=True)\n",
    "        values = values[counts>1]\n",
    "        values = sorted(list(values),reverse=True)[:np.min([len(values),2])]       \n",
    "        metres_list = [[y[1] for y in metre_list if y[0] == val] for val in values]\n",
    "\n",
    "        # Now, find per line length the most commonly predicted metre. In case of a tie, pick one at random.\n",
    "        # Sorry, best we can do for now...\n",
    "        result = list()\n",
    "        for metres_per_line_length in metres_list:\n",
    "            flat_list = [item for sublist in metres_per_line_length for item in sublist]\n",
    "            (values,counts) = np.unique(flat_list,return_counts=True)\n",
    "            ind=np.where(counts==np.max(counts))\n",
    "            if len(ind[0])>1:\n",
    "                result.append(np.random.choice(values[ind]))\n",
    "            else:\n",
    "                result.append(values[ind][0])\n",
    "    else:\n",
    "        result = 'unknown'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['metre_list'] = [get_known_metre(x) for x in df['scansion_altered']]\n",
    "df['metre'] = [', '.join(x) for x in df['metre_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print('\\n\\n--------')\n",
    "    print(i)\n",
    "    print2(df['poem'].iloc[i])\n",
    "    print(df['scansion_altered'].iloc[i])\n",
    "    print(df['metre'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_common_metres = (df\n",
    "                         .groupby('metre')\n",
    "                         .agg(n=('ups', len), \n",
    "                              avg_ups=('ups', 'mean'))\n",
    "                         .sort_values('n',ascending=False)\n",
    "                        )\n",
    "df_most_common_metres.reset_index(inplace=True)\n",
    "df_most_common_metres_10 = df_most_common_metres.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_horizontal_bar(\n",
    "    labels = df_most_common_metres_10['metre'][::-1],\n",
    "    values = df_most_common_metres_10['n'][::-1],\n",
    "    title = 'The 10 most common metres in poems by /u/poem_for_your_sprog',\n",
    "    xaxis_title = 'Number of poems',\n",
    "    yaxis_title='',\n",
    "    figsize=(800,500)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for metre in df_most_common_metres_10['metre']:\n",
    "    df_subset = df_most_common_metres_10[df_most_common_metres_10['metre'] == metre]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_subset['n'],\n",
    "        y=df_subset['avg_ups'],\n",
    "        mode='markers',\n",
    "        name=metre,\n",
    "        marker=dict(\n",
    "            size = 8,\n",
    "            line_width=1,\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        hoverinfo = 'text',\n",
    "        text= ['{}<br>Average upvotes: {}<br>n: {}'.format(row['metre'],round(row['avg_ups'],1),row['n'])  \n",
    "               for index, row in (df_subset).iterrows()]\n",
    "    )\n",
    " )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Number of poems vs average number of upvotes of the 10 most common metres<br> by u/poem_for_your_sprog',\n",
    "    title_x=0.5,\n",
    "    template='simple_white',\n",
    "    xaxis_title='n',\n",
    "    yaxis_title='Average upvotes'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_metres = df[df['metre'].isin(df_most_common_metres_10['metre'])]\n",
    "df_top_metres = (df_top_metres\n",
    "                 .groupby([\"metre\"])\n",
    "                 .apply(lambda x: x.sort_values([\"ups\"], ascending = False))\n",
    "                 .reset_index(drop=True)\n",
    "                 .groupby('metre')\n",
    "                 .head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for metre in df_most_common_metres_10['metre']:\n",
    "    df_subset = df_top_metres[df_top_metres['metre'] == metre]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_subset['average_line_length'],\n",
    "        y=df_subset['ups'],\n",
    "        mode='markers',\n",
    "        name=metre,\n",
    "        marker=dict(\n",
    "            size = 8,\n",
    "            line_width=1,\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        hoverinfo = 'text',\n",
    "        text=[re.sub('>','<br>',comment) for comment in df_subset['poem']]\n",
    "    )\n",
    " )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Top rated poems in the 10 most common metres by u/poem_for_your_sprog',\n",
    "    title_x=0.5,\n",
    "    template='simple_white',\n",
    "    xaxis_title='Average line length',\n",
    "    yaxis_title='Upvotes'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
