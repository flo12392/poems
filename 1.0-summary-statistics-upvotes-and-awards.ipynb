{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am a really big fan of the poems by [/u/poem_for_your_sprog](https://www.reddit.com/user/Poem_for_your_sprog/) on Reddit. For those of you who are not familiar with him yet; he writes short poems as responses to others on [/r/AskReddit](https://www.reddit.com/r/AskReddit/) threads. To give you an example, one that I particularly like is the following, which was written in response to a thread full of responses from ICU workers, who despite their best efforts are not always able to save every patient they meet:\n",
    "\n",
    "```\n",
    "You’ll weather the wind and the rain and the rough -\n",
    "And sometimes you’ll try but it won’t be enough.\n",
    "\n",
    "You did what you could,\n",
    "but it’s not up to you.\n",
    "\n",
    "You did what you could,\n",
    "and that’s all you can do.\n",
    "```\n",
    "[Source](https://www.reddit.com/r/AskReddit/comments/bj4hfq/medical_workers_of_reddit_what_were_the_most/em5vsum/)\n",
    "\n",
    "\n",
    "I always find it difficult to explain why I love these poems so much. Some, like the above, stand out in simplicity; six short lines that bring a message that speaks to many of us. But there's more elaborate ones, and really funny ones too. I would love to understand a little bit better what exactly it is that makes these poems so appealing to me, and to get a better grasp of the artform behind it. Sadly, I know absolutely nothing about poetry. And since I'm also not as good with words as [/u/poem_for_your_sprog](https://www.reddit.com/user/Poem_for_your_sprog/), I will try to understand poetry in the only way I know how: By using data.\n",
    "\n",
    "My plan is to create a dataset of all the poems [/u/poem_for_your_sprog](https://www.reddit.com/user/Poem_for_your_sprog/) has written, and create a number of notebooks that dive into these works. In this first notebook, I want to explore some basic statistics about these poems.\n",
    "\n",
    "You can find the notebook with python code that was used to create this page on [GitHub](https://github.com/flo12392/poems/blob/master/1.0-summary-statistics-upvotes-and-awards.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt \n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=False)\n",
    "\n",
    "from src.utils import print2_list, print2, export_ipynb_for_github_pages\n",
    "from src.plotly import plot_histogram, plot_timeline, plot_horizontal_bar, plot_heatmap, plot_scatter, plot_events_timeline\n",
    "from src.data import load_data\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "df = load_data('data/comments.txt', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments per day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by simply looking at the amount of poems over time. We can see below that on the extraordinarily productive days, sprog provides us with about 5 or 6 poems, and his productivity seems to have increased somewhat over time. The outlier of 12 comments in June is the ['Ask Me Anything'](https://www.reddit.com/r/books/comments/3aungz/hi_im_sam_garland_aka_upoem_for_your_sprog_ive/), or AMA in short, where he answered questions of fellow Redditors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments_per_day= df.groupby(['date'])['date'].agg(n='count')\n",
    "idx = pd.date_range(df_comments_per_day.index.min(), dt.datetime.today())\n",
    "df_comments_per_day = df_comments_per_day.reindex(idx, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_timeline(\n",
    "    x=df_comments_per_day.index,\n",
    "    y=df_comments_per_day['n'],\n",
    "    title='Number of comments on Reddit per day by u/poem_for_your_sprog',\n",
    "    xaxis_title='Day',\n",
    "    yaxis_title='Number of comments',\n",
    "    annotations=[\n",
    "        go.layout.Annotation(\n",
    "            x='2015-6-23',\n",
    "            y=12,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "            text=\"AMA\",\n",
    "            showarrow=True,\n",
    "            arrowhead=2,\n",
    "            ax=-50,\n",
    "            ay=0\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot was usful to determine the AMA outlier, so lets remove the observations from that day from our dataset. However, the daily plot does not really help us in identifying a trend, so let's aggregate the data to monthly buckets to get a clearer view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove AMA comments\n",
    "df = df[df['date']!=dt.date(2015,6,23)]\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_per_month = df_comments_per_day.groupby(pd.Grouper(freq='M'))['n'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_timeline(\n",
    "    x=comments_per_month.index,\n",
    "    y=comments_per_month,\n",
    "    title='Number of comments on Reddit per month by u/poem_for_your_sprog',\n",
    "    xaxis_title='Month',\n",
    "    yaxis_title='Number of comments'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all poems by sprog have been posted on /r/AskReddit threads, he also responded to posts on some other subreddits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In total, there are {} comments by /u/poem_for_your_sprog on Reddit. \\nOut of those, {:.1f}% were comments within /r/AskReddit.'\n",
    "      .format(len(df), \n",
    "              len(df[df['subreddit_name_prefixed']=='r/AskReddit'])/len(df)*100)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be interesting to find out to which other subreddits sprog has posted his poems in the past. To gain insight in the temporary pattern of these poems and in the distribution of these poems over the subreddits simultaneously, we can create a plot with multiple timelines and denote the comments as events in a scatter plot. You can hover over the plot to read the poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poem_per_sub = df[df['subreddit_name_prefixed']!='r/AskReddit'][['subreddit_name_prefixed','date','poem','ups']]\n",
    "df_poem_per_sub['poem_ups'] = ['Upvotes: {}>'.format(row['ups']) + row['poem'] for ix, row in df_poem_per_sub.iterrows()]\n",
    "df_poem_per_sub = (\n",
    "    df_poem_per_sub\n",
    "    .groupby(['subreddit_name_prefixed','date'])['poem_ups']\n",
    "    .agg(poem_ups =  lambda x: '>---->'.join(list(x)), count = len)\n",
    "    .reset_index(inplace=False)\n",
    ")\n",
    "df_poem_per_sub['subreddit_total'] = (\n",
    "    df_poem_per_sub['count']\n",
    "    .groupby(df_poem_per_sub['subreddit_name_prefixed'])\n",
    "    .transform('sum')\n",
    ")\n",
    "df_poem_per_sub = df_poem_per_sub.sort_values('subreddit_total')\n",
    "\n",
    "fig = plot_events_timeline(\n",
    "    x = df_poem_per_sub['date'],\n",
    "    y = df_poem_per_sub['subreddit_name_prefixed'],\n",
    "    text=[\"Total poems: {}<br>----<br>\".format(row['count']) + re.sub('>','<br>',row['poem_ups']) for ix,row in df_poem_per_sub.iterrows()],\n",
    "    title = 'Timeline of poems outside of /r/AskReddit by /u/poem_/for_your_sprog',\n",
    "    xaxis_title = 'Date',\n",
    "    yaxis_title = ''\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of subreddits that sprog has written poems on is fairly limited. It's also clear to see that in the early days there were many more comments outside of [/r/AskReddit](https://www.reddit.com/r/AskReddit/) threads than there have been in the past few years. \n",
    "\n",
    "It also seems like we have some more outliers to filter. For example, by hovering over the marker in December in the timeline of [/r/worldnews](https://www.reddit.com/r/worldnews/) we find a very long line that is clearly not part of a poem; that's a regular comment. So let's continue by analyzing the basic structure of the comments to see if we can identify a method to filter out these outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average line length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprog writes both poems with very short lines, as well as poems with longer ones. A histogram of the average number of characters on a line per poem should give us a better idea of the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plot_histogram(\n",
    "    x = df['average_line_length'],    \n",
    "    params = {'xbins':dict(start=0,end=200,size=1)},\n",
    "    title = 'Histogram of the average characters per line by u/poem_for_your_sprog',\n",
    "    xaxis_title = 'Number of characters',\n",
    "    yaxis_title = 'Number of poems'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three clear outliers, which upon further inspection are not poems, or contain a lot of text alongside the poem. We will filter those out for now. Furthermore, the peak around 46 is interesting to see. My initial guess was that some rhymes are written in the rhyme scheme `abab`, while others are split out over shorter lines in the rhyme shape `abcb defe`, so the former would on average have lines twice as long as the latter. But that does not seem to hold; then the first peak should be around 23 instead of 30.\n",
    "\n",
    "When I took a look at the rows corresponding to that peak, I found out that they all had a similar 'flow' to them. A bit of Googling made me relaize that this is called poetic [metre](https://en.wikipedia.org/wiki/Metre_(poetry)). There, I learned something about poetry already. It turns out that these are a set of poems that sprog usually writes in 'Anapestic tetrameter'. Anapestic tetrameter is a metre with four anapestical feet per line. An anapestical foot is two unstressed syllables, followed by a stressed one. So, denoting a stressed syllable as / and an unstressed syllable as x, an anapestic tetrameter can de denoted as follows:\n",
    "\n",
    "> x x / x x / x x / x x /\n",
    "\n",
    "However, sprog usually omits the first unstressed syllable, so it becomes:\n",
    "\n",
    ">   x / x x / x x / x x /\n",
    "\n",
    "To get a better idea, here is an example of one of these poems:\n",
    "\n",
    "```\n",
    "you don't need a measure of treasure to fly\n",
    "to sporting success on a broom in the sky...\n",
    "to eros alone in the sight of the stars...\n",
    "to space on a ship that's intended for mars.\n",
    "you don't need a mountain of money to go\n",
    "where peter and susan await in the snow...\n",
    "where planets contend and defend for a spice...\n",
    "where alice adventures with hatters and mice.\n",
    "you don't need a wallet of wealth and of worth\n",
    "to start on a journey across middle earth...\n",
    "to fight in the night with your sword and your steed.\n",
    "you don't need a fund or a fortune to read.\n",
    "```\n",
    "[Source](https://www.reddit.com/r/AskReddit/comments/5tek1p/what_is_a_great_poor_person_hobby/ddm5vcl/\t)\n",
    "\n",
    "\n",
    "I feel there's a lot more to learn about metre. But that seems to be a very broad topic, so let's save that for another notebook, and let's try to get a better feeling of the basic structure of the poems first. For example, it would be interesting to take a look at some of the poems with very short or very long line lengths to see what they look like. However, listing all the poems here would make this notebook quite long, so let's just plot them. In the figure below, I have put the 100 poems with the shortest average line length and the the 100 poems with the longest average line length in a plot that allows you to read the poems by hovering over the points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['average_line_length']<55]\n",
    "df = df[df['poem'].apply(len)>0]\n",
    "df = df[df['number_of_lines']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df.sort_values('average_line_length').head(100)\n",
    "df_long = df.sort_values('average_line_length',ascending=False).head(100)\n",
    "df_short_long = pd.concat([df_short,df_long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_scatter(\n",
    "    x=df_short_long['average_line_length'],\n",
    "    y=df_short_long['ups'],\n",
    "    text=[re.sub('>','<br>',row['poem']) for ix, row in df_short_long.iterrows()],\n",
    "    title='100 poems with the shortest and 100 poems with the <br>longest line length by u/poem_for_your_sprog',\n",
    "    xaxis_title='Average line length',\n",
    "    yaxis_title='Upvotes'\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're done reading, let's move on to another histogram; the number of lines per poem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_histogram(\n",
    "    x = df['number_of_lines'],    \n",
    "    params = {'xbins':dict(size=1)},\n",
    "    title = 'Histogram of the number of lines per poem by u/poem_for_your_sprog',\n",
    "    xaxis_title = 'Number of lines',\n",
    "    yaxis_title = 'Number of comments'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like something one might expect as well; poems usually have an even amount of lines, since we usually rhyme one line with another. The most common rhyme schemes I can think of are `abab`, and `abcb`, so it also makes sense that the highest peaks are at 4, 8, 12, and 16, which are multiples of four.\n",
    "\n",
    "The values directly following those numbers (5, 9, 13 and 17) also are relatively high. This seems to be caused by a characteristic way of breaking the last line into two lines to build some tension or to give some extra stress to the final line. An example:\n",
    "\n",
    "\n",
    "```\n",
    "you're disturbed and defiled and depraved and debased?\n",
    "you're obscene and corrupt and debauched and disgraced?\n",
    "you're perverse and profane and you freely confess?\n",
    "and with pride, he replied with a confident\n",
    "... yes.\n",
    "```\n",
    "[Source](https://www.reddit.com/r/AskReddit/comments/c4xbbn/people_who_have_found_their_friends_secret_reddit/erzjnhf/)\n",
    "\n",
    "And sometimes multiple lines in a poem are split up, or one line is split up into more than two parts, explaining the fact that the peak after each multiple of four decays until the next multiple of four. An example of this:\n",
    "\n",
    "```\n",
    "and when the darkness comes for me\n",
    "to take me where i'm meant to be -\n",
    "to guide me out beyond the black,\n",
    "forever on,\n",
    "and never back -\n",
    "to lead me through the final door\n",
    "till all that is and was before\n",
    "is nothing more than dreams at night -\n",
    "i will not fret.\n",
    "i will not fight.\n",
    "```\n",
    "[Source](/r/AskReddit/comments/99q9n5/redditors_who_have_been_clinically_dead_what_did/e4q0a2w/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upvotes & Awards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Reddit, there are two ways to show appreciation for a comment. One can upvote a post, of spend some actual money to give the post an award. Let's start by simply counting the upvotes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of upvotes on poems by /u/poem_for_your_sprog: {:,}'.format(df['ups'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that a lot? In order to find out, let's try to express it in Big Mac's. Here is a little thing I found on the internet (so it must be true):\n",
    "\n",
    "> According to research conducted by Vanderbilt University Medical Center, laughing for 10 to 15 minutes burns between 10 and 40 calories a day.\n",
    "\n",
    "Let's first assume that smiling is on the bottom of this spectrum, i.e. 15 minutes of smiling consumes 10 calories. Now let's assume that an upvote equals a second of smiling on average. Then we now have enough information to convert our number of upvotes to Big Mac's!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_per_sec = 10/(15*60)\n",
    "cal_per_smile = cal_per_sec * 1\n",
    "total_cals_smiled = df['ups'].sum() * cal_per_smile\n",
    "cal_per_big_mac = 564\n",
    "n_big_mac = round(total_cals_smiled/cal_per_big_mac,1)\n",
    "print('Calories per second of smiling: {0:.4f}'.format(cal_per_sec))\n",
    "print('Calories per smile: {0:.4f}'.format(cal_per_smile))\n",
    "print('Number of smiles: {:,}'.format(df['ups'].sum()))\n",
    "print('Total calories smiled: {0:,.1f}'.format(total_cals_smiled))\n",
    "print('Calories per Big Mac: {0:.1f}'.format(cal_per_big_mac))\n",
    "\n",
    "print('In total, {} Big Mac\\'s worth of calories have been consumed by smiles that were caused by poems by /u/poem_for_your_sprog.'\n",
    "     .format(n_big_mac))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer; I am not a dietician nor a physicist. Experimental results are needed to verify the above, but I have not found any volunteers yet. Please let me know if you're interested in participating.\n",
    "\n",
    "Next, let's take a look at the awards that sprog has earned. There are (at least) three types of awards;\n",
    "- Silver, granting the user.. nothing.\n",
    "- Gold, granting the user Reddit Premium for a week\n",
    "- Platinum, granting the user Reddit Premium for a month\n",
    "\n",
    "Below is a pie chart that shows the breakdown of the awards /u/poem_for_your_sprog has been given. Yes, I know many people don't like pie charts. Although I dough not really care, I have added a hole in the middle to make it a donut chart. As long as it's food related I'm happy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter()\n",
    "for d in df['awards_dict']:\n",
    "    c.update(d)\n",
    "\n",
    "color_dict = {'Gold': '#C9B037', \n",
    "          'Silver': '#D7D7D7', \n",
    "          'Platinum': '#B4B4B4'}\n",
    "colors = [color_dict[x] if x in color_dict else '#AD8A56' for x in [x[0] for x in c.items()]]\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "                    go.Pie(\n",
    "                        labels=[x[0] for x in c.items()], \n",
    "                        values=[x[1] for x in c.items()],\n",
    "                        marker=dict(colors=colors),\n",
    "                        textinfo='value', \n",
    "                        hoverinfo='label+percent',\n",
    "                        textfont_size=12,\n",
    "                        hole=.3 \n",
    "                    )\n",
    "    ]\n",
    ")\n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    title = 'Awards received on poems by /u/poem_for_your_sprog.',\n",
    "    title_x = 0.5,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of gold! Almost matches China's aspirations for the Olympic Games in 2028.\n",
    "\n",
    "Below are three more graphs. The first is a histogram of the number of upvotes per post, and the second is a histogram of the number of awards per post. The last graph shows the 100 most upvoted poems and the 100 poems with the most awards written by /u/poem_for_your_sprog on Reddit with the number of upvotes on the y-axis and the number of awards on the x-axis. You can hover over the points to read the poems!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_histogram(\n",
    "    x = df['ups'],    \n",
    "    params = {'xbins':dict(size=250)},\n",
    "    title = 'Histogram of the upvotes on poems by u/poem_for_your_sprog',\n",
    "    xaxis_title = 'Upvotes',\n",
    "    yaxis_title = 'Number of comments'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_histogram(\n",
    "    x = df['total_awards_received'],    \n",
    "    params = {'xbins':dict(size=1)},\n",
    "    title = 'Histogram of the number of awards per comment by u/poem_for_your_sprog',\n",
    "    xaxis_title = 'Number of awards',\n",
    "    yaxis_title = 'Number of comments'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_awards = df['total_awards_received'].sort_values(ascending=False).index[:100]\n",
    "top_upvotes = df['ups'].sort_values(ascending=False).index[:100]\n",
    "top_poems = top_awards.union(top_upvotes)\n",
    "df_top = df.loc[top_poems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_scatter(\n",
    "    x=df_top['total_awards_received'],\n",
    "    y=df_top['ups'],\n",
    "    text=['ups: {}<br>{}<br><br>'.format(row['ups'],row['awards_simple']) \n",
    "                  + re.sub('>','<br>',row['poem']) for index, row in (df_top).iterrows()],\n",
    "    title='Upvotes versus number of awards of the top poems by u/poem_for_your_sprog',\n",
    "    xaxis_title='Number of awards received',\n",
    "    yaxis_title='Upvotes'\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hovering over the right side of the plot, we find quite some poems that have many lines, which might lead us to believe that longer poems are awarded with silver, gold or platinum more often. The correlation plot below confirms that; the number of awards and the number of lines have a positive correlation.\n",
    "Also, in the plot we find two things that we might have expected to find; score and total awards received are positively correlated, and poems with many lines have in general a lower average line length, although the correlation coefficient of the latter is not very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df[['score','total_awards_received','average_line_length','number_of_lines']].corr()\n",
    "df_corr[df_corr==1]=np.nan\n",
    "\n",
    "fig = plot_heatmap(\n",
    "    z = df_corr.values,\n",
    "    x = df_corr.columns,\n",
    "    y = df_corr.columns,\n",
    "    title = 'Correlation plot',\n",
    "    figsize = (600,500)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's enough exploring poems for now! This helped in providing a better sense of the data by doing some initial exploration, but I think there's still a lot to find that can help me understand the art behind the poems better. In a next notebook I will try to dive a bit deeper into the things that make a poem a poem, such as meter or rhyme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_matter_str = \"\"\"---\n",
    "layout: post\n",
    "title: Poetry & Data - Part 1\n",
    "subtitle: Analyzing the comment history of /u/poem_for/your_sprog on Reddit\n",
    "tags: [python, poetry, poem_for_your_sprog, reddit]\n",
    "layout: html_post\n",
    "---\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "display(Javascript('IPython.notebook.save_checkpoint();'))\n",
    "import time\n",
    "time.sleep(10)\n",
    "export_ipynb_for_github_pages(filename=\"1.0-summary-statistics-upvotes-and-awards.ipynb\",\n",
    "                              front_matter_str=front_matter_str,\n",
    "                              prefix = dt.datetime.today().strftime('%Y-%m-%d') +'-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
