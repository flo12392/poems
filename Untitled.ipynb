{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "from src.reddit_user_comment_reader import RedditUserCommentReader\n",
    "from src.utils import print2_list\n",
    "from src.string import clean_comment\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_comments = True\n",
    "file_name = 'data/comments.txt'\n",
    "if os.path.isfile(file_name):\n",
    "    mtime = os.path.getmtime(file_name)\n",
    "    print(\"last modified: %s\" % dt.datetime.fromtimestamp(mtime))\n",
    "    if (dt.datetime.now() - dt.datetime.fromtimestamp(mtime)).seconds<24*60*60: # if modified in last 24 hours\n",
    "        download_comments = False\n",
    "\n",
    "if download_comments:\n",
    "    print('Downloading comments...')\n",
    "    reddit_user_comment_reader = RedditUserCommentReader('poem_for_your_sprog', verbose = True)\n",
    "    all_comments = reddit_user_comment_reader.get_comments()\n",
    "    print('Saving to file...')\n",
    "    with open(file_name, 'w') as outfile:\n",
    "        json.dump(all_comments, outfile)\n",
    "else:   \n",
    "    print('Loading comments from file...')\n",
    "    with open(file_name, 'r') as infile:\n",
    "        all_comments = json.load(infile)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = df['created_utc'].apply(dt.datetime.fromtimestamp)\n",
    "df['date'] = df['datetime'].dt.date\n",
    "df['comment_cleaned'] = df['body'].apply(clean_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments_per_day= df.groupby(['date','author'])['date'].agg(n='count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_comments_per_day['date'][df_comments_per_day['author']=='Poem_for_your_sprog'],\n",
    "                         y=df_comments_per_day['n'][df_comments_per_day['author']=='Poem_for_your_sprog'],\n",
    "                    mode='lines',\n",
    "                    name='lines'))\n",
    "fig.add_trace(go.Scatter(x=df_comments_per_day['date'][df_comments_per_day['author']=='[deleted]'],\n",
    "                         y=df_comments_per_day['n'][df_comments_per_day['author']=='[deleted]'],\n",
    "                    mode='lines',\n",
    "                    name='lines'))\n",
    "fig.update_layout(title='Number of comments on Reddit per day by u/poem_for_your_sprog',\n",
    "                  title_x=0.5,\n",
    "                   xaxis_title='Day',\n",
    "                   yaxis_title='Number of comments')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_comments_per_day,on='date',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average line length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['linebreaks'] = df['comment_cleaned'].apply(lambda x: sum(1 for _ in re.finditer(r'>', x)))\n",
    "df['comment_length']= df['comment_cleaned'].str.len()\n",
    "df['average_line_length'] = df['comment_length']/df['linebreaks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=df['average_line_length'],    \n",
    "       xbins=dict( # bins used for histogram\n",
    "        start=0,\n",
    "        end=200,\n",
    "        size=1,\n",
    "    )))\n",
    "fig.update_layout(title='Histogram of the average characters per line by u/poem_for_your_sprog',\n",
    "                  title_x=0.5,\n",
    "                   xaxis_title='Day',\n",
    "                   yaxis_title='Number of comments')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print2_list(df[df['average_line_length']>75]['comment_cleaned']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['average_line_length']<=75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "comments = df['comment_cleaned'].str.cat(sep=' ')\n",
    "tokens = tokenizer.tokenize(comments)\n",
    "tokens = [t for t in tokens if not t in stop_words ]\n",
    "frequency_dist = nltk.FreqDist(tokens)\n",
    "most_common = frequency_dist.most_common(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    y=[x[0] for x in most_common[::-1]],\n",
    "    x=[x[1] for x in most_common[::-1]],\n",
    "    name='SF Zoo',\n",
    "    orientation='h'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "        width=800, \n",
    "        height=900,\n",
    "        title='Most occuring words in comments by u/poem_for_your_sprog',\n",
    "        title_x=0.5,\n",
    "        xaxis_title='Occurence',\n",
    "        yaxis_title='',\n",
    "        yaxis=dict(\n",
    "            tickfont=dict( size=10),\n",
    "            tickvals=[x[0] for x in most_common[::-1]]\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about Timmy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_about_timmy = np.array(['timmy' in comment for comment in df['comment_cleaned']])\n",
    "print('Comments about Timmy: {}'.format(comments_about_timmy.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_about_timmy_fucking_dying = np.array(['timmy fucking died' in comment for comment in df['comment_cleaned']])\n",
    "print('Comments about Timmy fucking dying: {}'.format(comments_about_timmy.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print2_list(df['comment_cleaned'][(comments_about_timmy) & (~comments_about_timmy_fucking_dying)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.iloc[np.where((comments_about_timmy) & (~comments_about_timmy_fucking_dying))[0][1:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['comment_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['comment_cleaned'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
