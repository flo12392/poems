{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am a really big fan of the poems by /u/poem_for_your_sprog on Reddit. For those of you who are not familiar with him yet; he writes short poems as responses to others on AskReddit threads. To give you an example, one that I particularly like is the following, which was written in response to a thread of gripping stories by some ICU workers, who despite their best efforts are not always able to save every patient they meet:\n",
    "\n",
    "```\n",
    "You’ll weather the wind and the rain and the rough -\n",
    "And sometimes you’ll try but it won’t be enough.\n",
    "\n",
    "You did what you could,\n",
    "but it’s not up to you.\n",
    "\n",
    "You did what you could,\n",
    "and that’s all you can do.\n",
    "```\n",
    "\n",
    "I always find it difficult why I love these poems so much. Some, like the above, stand out in simplicity; six short lines that bring a message that speaks to many of us. But there's more elaborate ones, and really funny ones too. I think the one thing that they all have in common is their rhythm, or their 'flow'.\n",
    "\n",
    "However, since I am not as good with words as /u/poem_for_your_sprog, let me use numbers to analyze some of the work he has done to date!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt \n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=False)\n",
    "\n",
    "from src.utils import print2_list, print2\n",
    "from src.plotly import plot_histogram, plot_timeline, plot_horizontal_bar\n",
    "from src.data import load_data\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('data/comments.txt', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments per day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by simply looking at the amount of poems over time. We can see below that on the extraordinarily productive days, sprog provides us with about 5 or 6 poems, and his productivity seems to have increased somewhat over time. The outlier of 12 comments in June is the ['Ask Me Anything'](https://www.reddit.com/r/books/comments/3aungz/hi_im_sam_garland_aka_upoem_for_your_sprog_ive/), or AMA in short, where he answered questions of fellow Redditors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments_per_day= df.groupby(['date'])['date'].agg(n='count')\n",
    "idx = pd.date_range(df_comments_per_day.index.min(), dt.datetime.today())\n",
    "df_comments_per_day = df_comments_per_day.reindex(idx, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_timeline(\n",
    "    x=df_comments_per_day.index,\n",
    "    y=df_comments_per_day['n'],\n",
    "    title='Number of comments on Reddit per day by u/poem_for_your_sprog',\n",
    "    xaxis_title='Day',\n",
    "    yaxis_title='Number of comments',\n",
    "    annotations=[\n",
    "        go.layout.Annotation(\n",
    "            x='2015-6-23',\n",
    "            y=12,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "            text=\"AMA\",\n",
    "            showarrow=True,\n",
    "            arrowhead=2,\n",
    "            ax=-50,\n",
    "            ay=0\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot was usful to determine the AMA outlier, so lets remove the observations from that day from our dataset. However, the daily plot does not really help us in identiofying a trend, so let's aggregate the daya to monthly buckets to get a clearer view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove AMA comments\n",
    "df = df[df['date']!=dt.date(2015,6,23)]\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_per_month = df_comments_per_day.groupby(pd.Grouper(freq='M'))['n'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_timeline(\n",
    "    x=comments_per_month.index,\n",
    "    y=comments_per_month,\n",
    "    title='Number of comments on Reddit per month by u/poem_for_your_sprog',\n",
    "    xaxis_title='Month',\n",
    "    yaxis_title='Number of comments'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average line length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprog writes both poems with very short lines, as well as poems with longer ones. A histogram of the average number of characters on a line per poem should give us a better idea of the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plot_histogram(\n",
    "    x = df['average_line_length'],    \n",
    "    params = {'xbins':dict(start=0,end=200,size=1)},\n",
    "    title = 'Histogram of the average characters per line by u/poem_for_your_sprog',\n",
    "    xaxis_title = 'Day',\n",
    "    yaxis_title = 'Number of characters'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three clear outliers, which upon further inspection are not poems, or contain a lot of text alongside the poem. We will filter those out for now. Furthermore, the peak around 46 is interesting to see. My initial guess was that some rhymes are written in the rhyme scheme `abab`, while others are split out over shorter lines in the rhyme shape `abcb defe`, so the former would on average have lines twice as long as the latter. But that does not seem to hold; then the first peak should be around 23 instead of 30.\n",
    "\n",
    "It turns out that these are a set of poems that sprog usually writes in 'Anapestic tetrameter'. Anapestic tetrameter is a metre with four anapestical feet per line. An anapestical foot is two unstressed syllables, followed by a stressed one. So, denoting a stressed syllable as / and an unstressed syllable as x, an anapestic tetrameter can de denoted as follows:\n",
    "\n",
    "> x x / x x / x x / x x /\n",
    "\n",
    "However, sprog usually omits the first unstressed syllable, so it becomes:\n",
    "\n",
    ">   x / x x / x x / x x /\n",
    "\n",
    "To get a better idea, here is an example of one of these poems:\n",
    "\n",
    "```\n",
    "you don't need a measure of treasure to fly\n",
    "to sporting success on a broom in the sky...\n",
    "to eros alone in the sight of the stars...\n",
    "to space on a ship that's intended for mars.\n",
    "you don't need a mountain of money to go\n",
    "where peter and susan await in the snow...\n",
    "where planets contend and defend for a spice...\n",
    "where alice adventures with hatters and mice.\n",
    "you don't need a wallet of wealth and of worth\n",
    "to start on a journey across middle earth...\n",
    "to fight in the night with your sword and your steed.\n",
    "you don't need a fund or a fortune to read.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['average_line_length']<55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_histogram(\n",
    "    x = df['number_of_lines'],    \n",
    "    params = {'xbins':dict(size=1)},\n",
    "    title = 'Histogram of the number of lines per poem by u/poem_for_your_sprog',\n",
    "    xaxis_title = 'Number of lines',\n",
    "    yaxis_title = 'Number of comments'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's quite a wide spread! Some poems have on average lines that are three times longer than other poems. This makes one wonder what those poems look like.. Printing many poems here might not be the best solution, so let's put the 100 poems with the shortest average line length and the the 100 poems with the longest average line length in a plot that allows you to read the poems by hovering over the points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['poem'].apply(len)>0]\n",
    "df = df[df['number_of_lines']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df.sort_values('average_line_length').head(100)\n",
    "df_long = df.sort_values('average_line_length',ascending=False).head(100)\n",
    "df_short_long = pd.concat([df_short,df_long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "        data=go.Scatter(\n",
    "            x=df_short_long['average_line_length'],\n",
    "            y=df_short_long['ups'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size = 8,\n",
    "                line_width=1,\n",
    "                opacity=0.7\n",
    "            ),\n",
    "            hoverinfo = 'text',\n",
    "            text=[re.sub('>','<br>',comment) for comment in df_short_long['poem']]\n",
    "        )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='100 poems with the shortest and 100 poems with the longest line length <br> by u/poem_for_your_sprog',\n",
    "    title_x=0.5,\n",
    "    template='simple_white',\n",
    "    xaxis_title='Average line length',\n",
    "    yaxis_title='Upvotes'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upvotes & Awards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Redit, there are two ways fo showing appreciation for a comment. One can upvote a post, of spend some actual money to give the post an award. Let's start by simply counting the upvotes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of upvotes on poems by /u/poem_for_your_sprog: ' + str(df['ups'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a little thing I found on the internet, so it must be true:\n",
    "\n",
    "> According to research conducted by Vanderbilt University Medical Center, laughing for 10 to 15 minutes burns between 10 and 40 calories a day.\n",
    "\n",
    "Let's first assume that smiling is on the bottom of this spectrum, i.e. 15 minutes of smiling consumes 10 calories. Now let's assume that an upvote equals two seconds of smiling on average. Then we now have enough information to convert our number of upvotes to Big Mac's!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_per_sec = 10/(15*60)\n",
    "cal_per_smile = cal_per_sec * 2\n",
    "total_cals_smiled = df['ups'].sum() * cal_per_smile\n",
    "cal_per_big_mac = 564\n",
    "n_big_mac = round(total_cals_smiled/cal_per_big_mac,1)\n",
    "print('Calories per second of smiling: {0:.4f}'.format(cal_per_sec))\n",
    "print('Calories per smile: {0:.4f}'.format(cal_per_smile))\n",
    "print('Number of smiles: {}'.format(df['ups'].sum()))\n",
    "print('Total calories smiled: {0:.1f}'.format(total_cals_smiled))\n",
    "print('Calories per Big Mac: {0:.1f}'.format(cal_per_big_mac))\n",
    "\n",
    "print('In total, {} Big Mac\\'s worth of calories have been consumed by smiles that were caused by poems by /u/poem_for_your_sprog.'\n",
    "     .format(n_big_mac))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's take a look at the awards. There are (at least) three types of awards;\n",
    "- Silver, granting the user.. nothing.\n",
    "- Gold, granting the user Reddit Premium for a week\n",
    "- Platinum, granting the user Reddit Premium for a month\n",
    "\n",
    "Let's take a look at how many of each /u/poem_for_your_sprog has been given:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter()\n",
    "for d in df['awards_dict']:\n",
    "    c.update(d)\n",
    "\n",
    "color_dict = {'Gold': '#C9B037', \n",
    "          'Silver': '#D7D7D7', \n",
    "          'Platinum': '#B4B4B4'}\n",
    "colors = [color_dict[x] if x in color_dict else '#AD8A56' for x in [x[0] for x in c.items()]]\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "                    go.Pie(\n",
    "                        labels=[x[0] for x in c.items()], \n",
    "                        values=[x[1] for x in c.items()],\n",
    "                        marker=dict(colors=colors),\n",
    "                        textinfo='value', \n",
    "                        hoverinfo='label+percent',\n",
    "                        textfont_size=12,\n",
    "                        hole=.3 \n",
    "                    )\n",
    "    ]\n",
    ")\n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    title = 'Awards received on poems by /u/poem_for_your_sprog.',\n",
    "    title_x = 0.5,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_histogram(\n",
    "    x = df['ups'],    \n",
    "    params = {'xbins':dict(size=250)},\n",
    "    title = 'Histogram of the upss of poems by by u/poem_for_your_sprog',\n",
    "    xaxis_title = 'Upvotes',\n",
    "    yaxis_title = 'Number of comments'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_histogram(\n",
    "    x = df['total_awards_received'],    \n",
    "    params = {'xbins':dict(size=1)},\n",
    "    title = 'Histogram of the number of awards per comment by u/poem_for_your_sprog',\n",
    "    xaxis_title = 'Number of awards',\n",
    "    yaxis_title = 'Number of comments'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "        data=go.Scatter(\n",
    "            x=df['total_awards_received'],\n",
    "            y=df['ups'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size = 8,\n",
    "                line_width=1,\n",
    "                opacity=0.7\n",
    "            ),\n",
    "            hoverinfo = 'text',\n",
    "            text=['ups: {}<br>{}<br><br>'.format(row['ups'],row['awards_simple']) \n",
    "                  + re.sub('>','<br>',row['poem']) for index, row in df.iterrows()]\n",
    "        )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Upvotes versus number of awards of the poems by u/poem_for_your_sprog',\n",
    "    title_x=0.5,\n",
    "    template='simple_white',\n",
    "    xaxis_title='Number of awards received',\n",
    "    yaxis_title='Upvotes'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "comments = df['poem'].str.cat(sep=' ')\n",
    "tokens = tokenizer.tokenize(comments)\n",
    "tokens = [t for t in tokens if not t in stop_words]\n",
    "frequency_dist = nltk.FreqDist(tokens)\n",
    "most_common = frequency_dist.most_common(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_horizontal_bar(\n",
    "    labels = [x[0] for x in most_common[::-1]],\n",
    "    values = [x[1] for x in most_common[::-1]],\n",
    "    title = 'Most occuring words in comments by u/poem_for_your_sprog',\n",
    "    xaxis_title = 'Occurence',\n",
    "    yaxis_title='')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about Timmy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_about_timmy = np.array(['timmy' in comment for comment in df['poem']])\n",
    "comments_about_timmy_fucking_dying = np.array(['timmy fucking died' in comment for comment in df['poem']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comments about Timmy: {}'.format(comments_about_timmy.sum()))\n",
    "print('Comments about Timmy fucking dying: {}'.format(comments_about_timmy_fucking_dying.sum()))\n",
    "print('Comments about Timmy that do not end with Timmy fucking dying: {}'\n",
    "      .format(comments_about_timmy.sum()-comments_about_timmy_fucking_dying.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "                    go.Pie(\n",
    "                        labels=['Timmy fucking dying','Timmy not fucking dying'], \n",
    "                        values=[comments_about_timmy_fucking_dying.sum(),\n",
    "                             comments_about_timmy.sum()-comments_about_timmy_fucking_dying.sum()], hole=.3\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.update_layout(\n",
    "        template='simple_white'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So.. What happens to Timmy if he doesn't fucking die?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timmy_not_dying = df[(comments_about_timmy) & (~comments_about_timmy_fucking_dying)]\n",
    "df_timmy_not_dying['ending'] = [x.split('>')[-1] for x in df_timmy_not_dying['poem']]\n",
    "df_timmy_not_dying = df_timmy_not_dying.sort_values('ups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_horizontal_bar(\n",
    "    labels = df_timmy_not_dying['ending'],\n",
    "    values = df_timmy_not_dying['ups'],\n",
    "    title = 'Best scoring alternative endings to poems about Timmy',\n",
    "    xaxis_title = 'Upvotes',\n",
    "    yaxis_title=''\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rhyming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_word_per_line(poem):\n",
    "    return [re.findall(r\"\\s([^\\.?!,\\s]+)[\\.?!,\\s']*$\",line)[0] if re.findall(r\"\\s([^\\.?!,\\s]+)[\\.?!,\\s']*$\",line) else None \n",
    "     for line in poem.split('>')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_words_list = [get_last_word_per_line(mystr) for mystr in df['poem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def get_rhyme_scheme(last_words_per_line):\n",
    "    alphabet = string.ascii_lowercase\n",
    "    rhyme_scheme = np.empty(len(last_words_per_line),dtype=str)\n",
    "    k=0\n",
    "    for i in range(len(last_words_per_line)):\n",
    "        if rhyme_scheme[i]=='':\n",
    "            if last_words_per_line[i] is not None:\n",
    "                rhyme_scheme[i]=alphabet[k % 26]\n",
    "                rhyme_list = pronouncing.rhymes(last_words_per_line[i])\n",
    "                rhyme_scheme[(np.array([x in rhyme_list for x in last_words_per_line]) & (rhyme_scheme == ''))] = alphabet[k % 26]\n",
    "                k+=1\n",
    "            else:\n",
    "                rhyme_scheme[i] = '?'               \n",
    "    return ''.join(rhyme_scheme) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhyme_schemes = [get_rhyme_scheme(x) for x in last_words_list]\n",
    "df['rhyme_scheme'] = rhyme_schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_rhyme_schemes = df['rhyme_scheme'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_horizontal_bar(\n",
    "    labels = most_common_rhyme_schemes.index[::-1],\n",
    "    values = most_common_rhyme_schemes[::-1],\n",
    "    title = 'The 15 most common rhyming schemes in poems by /u/poem_for_your_sprog',\n",
    "    xaxis_title = 'Number of poems',\n",
    "    yaxis_title='',\n",
    "    figsize=(800,600)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_rhymes = df[df['rhyme_scheme'].isin(most_common_rhyme_schemes.index[:10])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_rhymes = (df_top_rhymes\n",
    "                 .groupby([\"rhyme_scheme\"])\n",
    "                 .apply(lambda x: x.sort_values([\"ups\"], ascending = False))\n",
    "                 .reset_index(drop=True)\n",
    "                 .groupby('rhyme_scheme')\n",
    "                 .head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for rhyme_scheme in most_common_rhyme_schemes.index[:10]:\n",
    "    df_subset = df_top_rhymes[df_top_rhymes['rhyme_scheme'] == rhyme_scheme]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_subset['average_line_length'],\n",
    "        y=df_subset['ups'],\n",
    "        mode='markers',\n",
    "        name=rhyme_scheme,\n",
    "        marker=dict(\n",
    "            size = 8,\n",
    "            line_width=1,\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        hoverinfo = 'text',\n",
    "        text=[re.sub('>','<br>',comment) for comment in df_subset['poem']]\n",
    "    )\n",
    " )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Top rated poems in the 10 most common rhyming schemes by u/poem_for_your_sprog',\n",
    "    title_x=0.5,\n",
    "    template='simple_white',\n",
    "    xaxis_title='Average line length',\n",
    "    yaxis_title='Upvotes'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rhyme sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rhyme_tuples(last_words_per_line):\n",
    "    all_rhymes = list()\n",
    "    for i in range(len(last_words_per_line)-1):\n",
    "        if last_words_per_line[i] is not None:\n",
    "            rhymes_with = pronouncing.rhymes(last_words_per_line[i])\n",
    "            next_words = last_words_per_line[(i+1):np.min([len(last_words_per_line),i+4])]\n",
    "            index_of_next_rhyme_words = np.where([x in rhymes_with for x in next_words])[0]\n",
    "            if index_of_next_rhyme_words.size>0:\n",
    "                all_rhymes.append((last_words_per_line[i], next_words[index_of_next_rhyme_words[0]]))\n",
    "    return all_rhymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "all_rhyme_tuples = [get_rhyme_tuples(x) for x in last_words_list]\n",
    "all_rhyme_tuples = reduce(lambda x,y: x+y,all_rhyme_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rhyme_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rhyme_words = [x for tpl in all_rhyme_tuples for x in tpl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rhyme_words = pd.DataFrame({'word':all_rhyme_words})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rhyme_words.groupby('word')['word'].count().sort_values(ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_scansion(word):\n",
    "    \"\"\" \n",
    "    Get the scansion per word, as a string of 0's and 1's.\n",
    "    \"\"\"\n",
    "    word = word.strip(punctuation)\n",
    "    if word == '': \n",
    "        return ''\n",
    "    pronounciation = pronouncing.phones_for_word(word)\n",
    "    if pronounciation: \n",
    "        stresses = pronouncing.stresses(pronounciation[0])\n",
    "    else:\n",
    "        word = re.sub(\"'.+\",'',word)\n",
    "        pronounciation = pronouncing.phones_for_word(word)\n",
    "        if pronounciation: \n",
    "            stresses = pronouncing.stresses(pronounciation[0])\n",
    "        else:\n",
    "            stresses = '?'\n",
    "    return re.sub('2','1',stresses)\n",
    "\n",
    "def get_line_scansion(line):\n",
    "    \"\"\" \n",
    "    Get the scansion per line, as a string of 0's and 1's.\n",
    "    \"\"\"\n",
    "    return ''.join([get_word_scansion(word) for word in line.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * = acatalectic, i.e. the last (unstressed) syllable is omitted\n",
    "# ** = iambic subsitution, i.e. the first (unstressed) syllable is omitted from an anapestic foot\n",
    "\n",
    "known_metres = {\n",
    "    'iambic hexameter'       : '010101010101',\n",
    "    'iambic pentameter'      : '0101010101',\n",
    "    'iambic tetrameter'      : '01010101',\n",
    "    'iambic trimeter'        : '010101',\n",
    "    'iambic dimeter'         : '0101',\n",
    "    'iambic meter'           : '01',\n",
    "    \n",
    "    'anapestic tetrameter'   : '001001001001',\n",
    "    'anapestic tetrameter**' : '01001001001',\n",
    "    'anapestic trimeter'     : '001001001',\n",
    "    'anapestic trimeter**'   : '01001001',\n",
    "    'anapestic dimeter'      : '001001',\n",
    "    'anapestic dimeter**'    : '01001',\n",
    "    'anapestic meter'        : '001',\n",
    "\n",
    "    'trochaic hexameter'     : '101010101010',\n",
    "    'trochaic hexameter*'    : '10101010101',\n",
    "    'trochaic pentameter'    : '1010101010',\n",
    "    'trochaic pentameter*'   : '101010101',\n",
    "    'trochaic tetrameter'    : '10101010',\n",
    "    'trochaic tetrameter*'   : '1010101',\n",
    "    'trochaic trimeter'      : '101010',\n",
    "    'trochaic trimeter*'     : '10101',\n",
    "    'trochaic bimeter'       : '1010',\n",
    "    'trochaic bimeter*'      : '101',\n",
    "    'trochaic meter'         : '10',\n",
    "}\n",
    "kown_metres_inv = inv_map = {v: k for k, v in known_metres.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scansion = [[get_line_scansion(line) for line in poem.split('>')] for poem in df['poem']]\n",
    "df['scansion'] = [list(filter(bool, x)) for x in scansion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_line_scansions(scansion_list):\n",
    "    \"\"\" \n",
    "    Combines multiple shorter lines into a single line, if the number of syllables is equal.\n",
    "    This turns for example the following list of scansions per line;\n",
    "    \n",
    "    ['11101001011',\n",
    "     '11101011001',\n",
    "     '111011',\n",
    "     '11011']\n",
    "     \n",
    "     into\n",
    "     \n",
    "     ['11101001011',\n",
    "      '11101011001',\n",
    "      '11101111011']\n",
    "    \n",
    "    \"\"\"   \n",
    "    scansion_list = scansion_list.copy()\n",
    "    \n",
    "    improvement_found = True\n",
    "    while improvement_found:\n",
    "        # Find which lines to combine into one, if any.\n",
    "        n_syllables_per_line = [len(x) for x in scansion_list]\n",
    "        unique_line_lengths = sorted(np.unique(np.array(n_syllables_per_line)), key=lambda item: -item)\n",
    "        for target_length in unique_line_lengths[:np.min([len(unique_line_lengths),2])]:\n",
    "            for lines_to_combine in [2,3,4]: # try to combine 2,3 or 4 lines.\n",
    "                idx_line_to_combine = []\n",
    "                if lines_to_combine<len(scansion_list):\n",
    "                    combined_line_lengths = np.convolve(n_syllables_per_line,np.ones(lines_to_combine,dtype=int),'valid')\n",
    "                    idx_line_to_combine = np.where(combined_line_lengths==target_length)[0]\n",
    "                    if len(idx_line_to_combine)>0: break\n",
    "            if len(idx_line_to_combine)>0: break\n",
    "\n",
    "        if len(idx_line_to_combine)>0:\n",
    "            improvement_found = True\n",
    "            new_line = ''.join(scansion_list[idx_line_to_combine[0]:(idx_line_to_combine[0]+lines_to_combine)])\n",
    "            scansion_list[idx_line_to_combine[0]] = new_line\n",
    "            del scansion_list[(idx_line_to_combine[0]+1):(idx_line_to_combine[0]+lines_to_combine)]\n",
    "        else:\n",
    "            improvement_found = False\n",
    "            \n",
    "    return scansion_list\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scansion_altered'] = [combine_line_scansions(x) for x in df['scansion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_non_stressed(a,b):\n",
    "    return sum ((a[i] == '0') and (b[i] == '0') for i in range(len(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_known_metre(scansion_list):\n",
    "    \"\"\"\n",
    "    Use a list of scansion per line to estimate the metre of the poem. The assumption is \n",
    "    that a poem always has at most two different known metres. Furthermore, since our method of\n",
    "    identifying the scansion overestimates the number of stressed syllables, we will use the number\n",
    "    of accurate non-stressed syllables to determine the known metre.\n",
    "    \"\"\"\n",
    "    # First, create metre_list; a list which elements have the structure [a,b] where a is the number \n",
    "    # of syllables in the line, and b a list of the most likely know metres.\n",
    "    metre_list=[]\n",
    "    for scansion in scansion_list:\n",
    "        l = [(same_non_stressed(scansion,k),v) for k, v in kown_metres_inv.items() if len(k) == len(scansion)]    \n",
    "        if l:\n",
    "            maxValue = max(l, key=lambda x: x[0])[0]\n",
    "            maxValueList = [x[1] for x in l if x[0] == maxValue]\n",
    "            metre_list.append([len(scansion),maxValueList])\n",
    "\n",
    "    # If metre_list has at least one element, create metres_list. The elements in this list\n",
    "    # contain per line length all the predicted metres, still to be flattened.\n",
    "    # If more than two elements, we only look at the stats for the two highest line lengths.\n",
    "    # this is to filter outliers, if in some shorter lines the metre was not found and thus they\n",
    "    # could not be combined.\n",
    "    if metre_list:        \n",
    "        (values,counts) = np.unique([x[0] for x in metre_list],return_counts=True)\n",
    "        values = values[counts>1]\n",
    "        values = sorted(list(values),reverse=True)[:np.min([len(values),2])]       \n",
    "        metres_list = [[y[1] for y in metre_list if y[0] == val] for val in values]\n",
    "\n",
    "        # Now, find per line length the most commonly predicted metre. In case of a tie, pick one at random.\n",
    "        # Sorry, best we can do for now...\n",
    "        result = list()\n",
    "        for metres_per_line_length in metres_list:\n",
    "            flat_list = [item for sublist in metres_per_line_length for item in sublist]\n",
    "            (values,counts) = np.unique(flat_list,return_counts=True)\n",
    "            ind=np.where(counts==np.max(counts))\n",
    "            if len(ind[0])>1:\n",
    "                result.append(np.random.choice(values[ind]))\n",
    "            else:\n",
    "                result.append(values[ind][0])\n",
    "    else:\n",
    "        result = 'unknown'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['metre_list'] = [get_known_metre(x) for x in df['scansion_altered']]\n",
    "df['metre'] = [', '.join(x) for x in df['metre_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print('\\n\\n--------')\n",
    "    print(i)\n",
    "    print2(df['poem'].iloc[i])\n",
    "    print(df['scansion_altered'].iloc[i])\n",
    "    print(df['metre'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_metres = df['metre'].value_counts().head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_horizontal_bar(\n",
    "    labels = most_common_metres.index[::-1],\n",
    "    values = most_common_metres[::-1],\n",
    "    title = 'The 10 most common metres in poems by /u/poem_for_your_sprog',\n",
    "    xaxis_title = 'Number of poems',\n",
    "    yaxis_title='',\n",
    "    figsize=(800,500)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_metres = df[df['metre'].isin(most_common_metres.index[:10])]\n",
    "df_top_metres = (df_top_metres\n",
    "                 .groupby([\"metre\"])\n",
    "                 .apply(lambda x: x.sort_values([\"ups\"], ascending = False))\n",
    "                 .reset_index(drop=True)\n",
    "                 .groupby('metre')\n",
    "                 .head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for metre in most_common_metres.index[:10]:\n",
    "    df_subset = df_top_metres[df_top_metres['metre'] == metre]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_subset['average_line_length'],\n",
    "        y=df_subset['ups'],\n",
    "        mode='markers',\n",
    "        name=metre,\n",
    "        marker=dict(\n",
    "            size = 8,\n",
    "            line_width=1,\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        hoverinfo = 'text',\n",
    "        text=[re.sub('>','<br>',comment) for comment in df_subset['poem']]\n",
    "    )\n",
    " )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Top rated poems in the 10 most common metres by u/poem_for_your_sprog',\n",
    "    title_x=0.5,\n",
    "    template='simple_white',\n",
    "    xaxis_title='Average line length',\n",
    "    yaxis_title='Upvotes'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
